{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nASH7mpNa6Dj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import GradientBoostingClassifier\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import log_loss\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","from lightgbm import LGBMClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBoUzrh8a-tc"},"outputs":[],"source":["# read in data\n","df = pd.read_csv ('train.csv')\n","df1 = pd.read_csv('test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCz2XC9zbEGc","outputId":"fcbe64c3-d78b-44b2-ed87-3a6b903782d5","executionInfo":{"status":"ok","timestamp":1648430104165,"user_tz":240,"elapsed":11352,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1199\n","6\n"]}],"source":["# Impute missing values using mode\n","imp_freq = SimpleImputer(strategy=\"most_frequent\")\n","i = 0\n","dele_list = []\n","ave_list = []\n","while i < 1205:\n","  name = 'x'+str(i+1)\n","  if df.iloc[:,i+3].isnull().sum() >= 17398:\n","    dele_list.append(name)\n","    i+=1\n","    continue\n","  value = df.iloc[:,i+3].values.reshape(-1,1)\n","  imp = imp_freq.fit_transform(value)\n","  col = df.iloc[:,i+3].dropna()\n","  values, counts = np.unique(col, return_counts=True)\n","  freq_ind = np.argmax(counts)\n","  ave_list.append(values[freq_ind])\n","  df.iloc[:,i+3] = imp\n","  i += 1\n","\n","print(len(ave_list))\n","print(len(dele_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MXjAjUUbfog","outputId":"e01a2f2f-b912-4761-f728-c1df734ae34f","executionInfo":{"status":"ok","timestamp":1648430454352,"user_tz":240,"elapsed":115,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['x96', 'x97', 'x98', 'x1021', 'x1098', 'x1099']\n"]}],"source":["print(dele_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMXP94zlbGh7"},"outputs":[],"source":["# data drop deleting columns\n","df.drop(columns=dele_list, inplace=True)\n","df1.drop(columns=dele_list, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLA_iywPbJrl"},"outputs":[],"source":["# imputation for test data set\n","i = 0\n","while i < len(ave_list):\n","  name = 'x'+str(i+1)\n","  df1.iloc[:, i+3].fillna(ave_list[i], inplace=True)\n","  i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVcwrVuGhbn1"},"outputs":[],"source":["df1[\"x80\"] = df[\"x80\"].map({1:0, 2:0, 4:0, 3:1})\n","df[\"x80\"] = df[\"x80\"].map({1:0, 2:0, 4:0, 3:1})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3SoJoxWhZJH","outputId":"eba956c5-c143-4f40-bfe8-bcf840b95e72","executionInfo":{"status":"ok","timestamp":1648430480733,"user_tz":240,"elapsed":7854,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1024, 1027, 1031, 1033, 1034, 1039, 16, 17, 20, 21, 1044, 1047, 536, 537, 1051, 1054, 1058, 548, 1061, 1065, 1068, 1072, 1075, 1079, 1082, 573, 574, 576, 1088, 580, 581, 583, 587, 588, 590, 78, 79, 81, 82, 83, 84, 85, 86, 87, 1110, 1111, 1133, 1135, 1144, 634, 635, 636, 637, 639, 653, 654, 659, 148, 149, 150, 661, 664, 668, 1175, 1180, 1184, 677, 678, 686, 690, 1202, 703, 707, 196, 197, 198, 199, 200, 754, 766, 767, 780, 781, 785, 787, 790, 804, 805, 811, 303, 304, 305, 837, 853, 867, 868, 872, 874, 877, 891, 892, 895, 896, 897, 911, 915, 919, 928, 929, 930, 944, 434, 435, 948, 952, 444, 965, 968, 970, 971, 974, 978, 980, 981, 472, 984, 474, 985, 476, 988, 990, 991, 994, 998, 1000, 1001, 1004, 1010, 1011, 1014, 1015, 1018, 1020, 1023, 213, 640]\n"]}],"source":["col_cat_list = [16,17,20,21,78,79,81,82,83,84,85,86,87,148,149,150,196,197,\n","         198,199,200,303,304,305,322,323,324,325,326,327,328,329,330,\n","         332,434,435,444,472,474,476,480,498,536,537,548,573,574,575,\n","         576,580,581,582,583,587,588,589,590,634,635,636,637,639,653,\n","         654,659,660,661,662,663,664,668,677,678,686,690,694,703,707,\n","         710,754,766,767,780,781,785,787,790,794,804,805,811,837,853,\n","         867,868,872,874,877,891,892,893,895,896,897,911,915,919,928,\n","         929,930,944,948,952,965,968,970,971,974,978,980,981,984,985,\n","         988,990,991,994,995,998,1000,1001,1004,1010,1011,1014,1015,\n","         1018,1020,1023,1024,1027,1031,1032,1033,1034,1039,1044,1047,\n","         1051,1054,1058,1061,1065,1068,1072,1075,1079,1082,1088,1110,\n","         1111,1118,1119,1120,1121,1122,1123,1124,1128,1133,1135,1143,\n","         1144,1146,1147,1149,1150,1175,1180,1184,1202]\n","add = [213, 640]\n","dele = [322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 480, \n","        498, 575, 582, 589, 660, 662, 663, 694, 710, 794, 893, \n","        995, 1032, 1118, 1119, 1120, 1121, 1122, 1123, 1124, \n","        1128, 1143, 1146, 1147, 1149, 1150]\n","def Diff(li1, li2):\n","     return list(set(li1) - set(li2))\n","\n","col_cat_list = Diff(col_cat_list, dele)\n","col_cat_list.extend(add)\n","print(col_cat_list)\n","# 164, \n","col_list = []\n","for i in range(len(col_cat_list)):\n","  col_list.append('x' + str(col_cat_list[i]))\n","\n","for col in col_list:\n","    df[col] = df[col].astype('category',copy=False)\n","    df1[col] = df1[col].astype('category',copy=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJMLjXDAqPKf","outputId":"5cb9e148-f5bd-4ec2-a6d9-e3d57e677bcf","executionInfo":{"status":"ok","timestamp":1648430485580,"user_tz":240,"elapsed":122,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["146\n"]}],"source":["print(len(col_cat_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcA7FsdQ0clA","outputId":"632dd5a4-4c98-430c-a2b4-a04666f556cc","executionInfo":{"status":"ok","timestamp":1648430487303,"user_tz":240,"elapsed":336,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["uniqueid       int64\n","year           int64\n","personid       int64\n","x1           float64\n","x2           float64\n","              ...   \n","x1202       category\n","x1203        float64\n","x1204        float64\n","x1205        float64\n","health         int64\n","Length: 1203, dtype: object"]},"metadata":{},"execution_count":10}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"HsOSQud5bNOB","outputId":"d8151d3d-e12a-42d9-8a9c-5239a3503d98","executionInfo":{"status":"ok","timestamp":1648430490230,"user_tz":240,"elapsed":172,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","  \"\"\"\n"]},{"output_type":"execute_result","data":{"text/plain":["       year  personid   x1   x2   x3   x4   x5   x6   x7   x8  ...  x1199  \\\n","0      2005      3999  5.0  3.0  5.0  4.0  3.0  2.0  5.0  7.0  ...    2.0   \n","1      2005      3997  3.0  3.0  3.0  3.0  3.0  2.0  5.0  7.0  ...    2.0   \n","2      2005      3996  4.0  4.0  3.0  3.0  3.0  2.0  5.0  7.0  ...    2.0   \n","3      2005      3995  3.0  2.0  3.0  3.0  3.0  2.0  5.0  7.0  ...    2.0   \n","4      2005      3993  4.0  2.0  4.0  4.0  3.0  2.0  2.0  7.0  ...    2.0   \n","...     ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n","17393  2017       514  3.0  3.0  3.0  3.0  3.0  2.0  3.0  7.0  ...    1.0   \n","17394  2017       513  3.0  3.0  4.0  4.0  3.0  2.0  5.0  7.0  ...    1.0   \n","17395  2017       512  2.0  2.0  2.0  2.0  3.0  2.0  2.0  7.0  ...    2.0   \n","17396  2017       511  2.0  2.0  4.0  3.0  3.0  2.0  8.0  7.0  ...    2.0   \n","17397  2017       510  2.0  2.0  3.0  3.0  3.0  2.0  7.0  7.0  ...    2.0   \n","\n","       x1200  x1201  x1202  x1203  x1204  x1205      new1 new2  new3  \n","0        1.0      2    160    1.0    4.0    2.0  0.726488    1    12  \n","1        1.0      2    140    3.0    5.0    2.0  0.350056    1     6  \n","2        1.0      2    140    3.0    5.0    2.0  0.721656    0     0  \n","3        1.0      2    150    1.0    5.0    2.0  0.621261    0    12  \n","4        1.0      2    130    5.0    8.0    2.0  0.104142    0     5  \n","...      ...    ...    ...    ...    ...    ...       ...  ...   ...  \n","17393    1.0      1     60    4.0    9.0    9.0  0.264383    1    18  \n","17394    1.0      1     80    6.0    8.0    7.0  0.817237    1    16  \n","17395    1.0      2    150    3.0    3.0    1.0  0.830638    0     1  \n","17396    2.0      1     90    3.0    4.0    7.0  0.204889    1     6  \n","17397    1.0      1    111    7.0   10.0    7.0  0.765285    1     6  \n","\n","[17398 rows x 1204 columns]"],"text/html":["\n","  <div id=\"df-154ccf98-e846-4138-9e2b-2d511b881fad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>personid</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>x3</th>\n","      <th>x4</th>\n","      <th>x5</th>\n","      <th>x6</th>\n","      <th>x7</th>\n","      <th>x8</th>\n","      <th>...</th>\n","      <th>x1199</th>\n","      <th>x1200</th>\n","      <th>x1201</th>\n","      <th>x1202</th>\n","      <th>x1203</th>\n","      <th>x1204</th>\n","      <th>x1205</th>\n","      <th>new1</th>\n","      <th>new2</th>\n","      <th>new3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2005</td>\n","      <td>3999</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>0.726488</td>\n","      <td>1</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2005</td>\n","      <td>3997</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>140</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>0.350056</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2005</td>\n","      <td>3996</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>140</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>0.721656</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2005</td>\n","      <td>3995</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>0.621261</td>\n","      <td>0</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2005</td>\n","      <td>3993</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>5.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>0.104142</td>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17393</th>\n","      <td>2017</td>\n","      <td>514</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>4.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>0.264383</td>\n","      <td>1</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>17394</th>\n","      <td>2017</td>\n","      <td>513</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>80</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>7.0</td>\n","      <td>0.817237</td>\n","      <td>1</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>17395</th>\n","      <td>2017</td>\n","      <td>512</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.830638</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17396</th>\n","      <td>2017</td>\n","      <td>511</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>8.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>7.0</td>\n","      <td>0.204889</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>17397</th>\n","      <td>2017</td>\n","      <td>510</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>111</td>\n","      <td>7.0</td>\n","      <td>10.0</td>\n","      <td>7.0</td>\n","      <td>0.765285</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17398 rows × 1204 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-154ccf98-e846-4138-9e2b-2d511b881fad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-154ccf98-e846-4138-9e2b-2d511b881fad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-154ccf98-e846-4138-9e2b-2d511b881fad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["y = df.iloc[:,-1]\n","x = df.drop(columns=['uniqueid', 'health'])\n","x['new1'] = np.random.uniform(0,1,17398)\n","x['new2'] = np.random.randint(0,2,17398)\n","x['new3'] = np.random.randint(low=0, high=20, size=17398)\n","#x['personid']= x['personid'].map(str)\n","x_columns = x.columns.values.tolist()\n","#print(x_columns)\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeuWOK8-bUjR","outputId":"03afc311-be53-4e92-9d71-3244b0172f6f","executionInfo":{"status":"ok","timestamp":1648430673644,"user_tz":240,"elapsed":175320,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1204\n"]}],"source":["clf_f_s = RandomForestClassifier(n_estimators=300, max_features=150, bootstrap=True, oob_score=True)\n","clf_f_s.fit(x,y)\n","f = clf_f_s.feature_importances_\n","f\n","print(len(f))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQX3_MzTbUd0","outputId":"855c5db5-ce29-4e22-dd7e-622d631eceaf","executionInfo":{"status":"ok","timestamp":1648430677204,"user_tz":240,"elapsed":95,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.008196195413027506 0.0010736128837024706 0.00544283547464917\n"]}],"source":["imp_new1 = f[1201]\n","imp_new2 = f[1202]\n","imp_new3 = f[1203]\n","dele_i_list = []\n","for i in range(len(f)):\n","  if f[i] <= imp_new1 and f[i] <= imp_new2 and f[i] <= imp_new3:\n","    dele_i_list.append(i)\n","print(imp_new1, imp_new2, imp_new3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PKibz-obcaQ","outputId":"50407df7-0001-4d34-ad18-b8c97d905bab","executionInfo":{"status":"ok","timestamp":1648430684162,"user_tz":240,"elapsed":84,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["941\n","1202\n"]}],"source":["print(len(dele_i_list))\n","print(max(dele_i_list))\n","dele_i_list.remove(max(dele_i_list))\n","df.drop(df.columns[dele_i_list], axis=1, inplace=True)\n","df1.drop(df1.columns[dele_i_list], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zp9PB9x1htQb"},"outputs":[],"source":["x, y = df.iloc[:,:-1],df.iloc[:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"vm20o22DsXmk","outputId":"71078e02-e5ae-46ec-dff6-14c7e890c2fb","executionInfo":{"status":"ok","timestamp":1648430687697,"user_tz":240,"elapsed":113,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       year  personid   x1   x2   x3   x6  x13  x16  x19  x110  ...  x1178  \\\n","0      2005      3999  5.0  3.0  5.0  2.0  3.0  1.0  1.0   3.0  ...    3.0   \n","1      2005      3997  3.0  3.0  3.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","2      2005      3996  4.0  4.0  3.0  2.0  3.0  1.0  1.0   3.0  ...    3.0   \n","3      2005      3995  3.0  2.0  3.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","4      2005      3993  4.0  2.0  4.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","...     ...       ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...   \n","17393  2017       514  3.0  3.0  3.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","17394  2017       513  3.0  3.0  4.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","17395  2017       512  2.0  2.0  2.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","17396  2017       511  2.0  2.0  4.0  2.0  3.0  1.0  1.0   3.0  ...    2.0   \n","17397  2017       510  2.0  2.0  3.0  2.0  3.0  1.0  1.0   3.0  ...    3.0   \n","\n","       x1180  x1182  x1183  x1184  x1201  x1202  x1203 x1204 x1205  \n","0        3.0      2     41      2      2    160    1.0   4.0   2.0  \n","1        3.0      1     49      5      2    140    3.0   5.0   2.0  \n","2        3.0      1     49      5      2    140    3.0   5.0   2.0  \n","3        3.0      1     74      5      2    150    1.0   5.0   2.0  \n","4        3.0      1     57      2      2    130    5.0   8.0   2.0  \n","...      ...    ...    ...    ...    ...    ...    ...   ...   ...  \n","17393    3.0      1     68      3      1     60    4.0   9.0   9.0  \n","17394    3.0      1     68      3      1     80    6.0   8.0   7.0  \n","17395    2.0      1     52      5      2    150    3.0   3.0   1.0  \n","17396    3.0      1     73      2      1     90    3.0   4.0   7.0  \n","17397    4.0      2     48      5      1    111    7.0  10.0   7.0  \n","\n","[17398 rows x 262 columns]"],"text/html":["\n","  <div id=\"df-ac337420-813b-456d-b639-200b5cd8e635\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>personid</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>x3</th>\n","      <th>x6</th>\n","      <th>x13</th>\n","      <th>x16</th>\n","      <th>x19</th>\n","      <th>x110</th>\n","      <th>...</th>\n","      <th>x1178</th>\n","      <th>x1180</th>\n","      <th>x1182</th>\n","      <th>x1183</th>\n","      <th>x1184</th>\n","      <th>x1201</th>\n","      <th>x1202</th>\n","      <th>x1203</th>\n","      <th>x1204</th>\n","      <th>x1205</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2005</td>\n","      <td>3999</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>41</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2005</td>\n","      <td>3997</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>49</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>140</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2005</td>\n","      <td>3996</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>49</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>140</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2005</td>\n","      <td>3995</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>74</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2005</td>\n","      <td>3993</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>57</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>5.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17393</th>\n","      <td>2017</td>\n","      <td>514</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>4.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>17394</th>\n","      <td>2017</td>\n","      <td>513</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>80</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>17395</th>\n","      <td>2017</td>\n","      <td>512</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>52</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>17396</th>\n","      <td>2017</td>\n","      <td>511</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>73</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>17397</th>\n","      <td>2017</td>\n","      <td>510</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>48</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>111</td>\n","      <td>7.0</td>\n","      <td>10.0</td>\n","      <td>7.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17398 rows × 262 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac337420-813b-456d-b639-200b5cd8e635')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ac337420-813b-456d-b639-200b5cd8e635 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ac337420-813b-456d-b639-200b5cd8e635');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["x"]},{"cell_type":"markdown","metadata":{"id":"ltxOXAzCZyEb"},"source":["# Light Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A8qsPLYRbicw"},"outputs":[],"source":["state = 0\n","test_size = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CE_LX7X-c4nX","outputId":"378385ab-05ee-4298-fc99-d36ef7530909"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.1716869642786794 0.48735632183908045 0.7725966374479092\n","1.1787693916518274 0.47902298850574715 0.774249173731858\n","1.1789361979712039 0.4781609195402299 0.7696508118982612\n","1.1974698596574802 0.4831848232250647 0.7785042028881385\n","1.1602393413221723 0.49209542972118425 0.7714634672031037\n"]}],"source":["clf_ls = []\n","kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","kf.get_n_splits(x)\n","sum1 = 0\n","sum2 = 0\n","sum3 = 0\n","\n","for train_index, test_index in kf.split(x):\n","  clf_lgbm = LGBMClassifier()\n","  x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","  y_train, y_test = y[train_index], y[test_index]\n","  # x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","  # clf_lgbm.fit(x_smote_resampled, y_smote_resampled)\n","  clf_lgbm.fit(x_train, y_train)\n","  a = log_loss(y_test, clf_lgbm.predict_proba(x_test))\n","  b = clf_lgbm.score(x_test, y_test)\n","  c = clf_lgbm.score(x_train, y_train)\n","  print(a, b, c)\n","  sum1 += a\n","  sum2 += b\n","  sum3 += c\n","clf_ls.append((sum1/5, sum2/5, sum3/5))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-28LkQueboZ","outputId":"f511d3d1-313b-4093-ec28-d733f1e97362"},"outputs":[{"data":{"text/plain":["[(1.1774203509762726, 0.4839640965662613, 0.7732928586338541)]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["clf_ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCESnMm9f3Xv","outputId":"a8ae0ef2-a8c2-49bd-cefa-40da2af83272"},"outputs":[{"name":"stdout","output_type":"stream","text":["n_estimators=10, loss=1.2361343999447705, test_score=0.4680434495313424, train_score=0.5327768162813278\n","n_estimators=20, loss=1.1978083632219345, test_score=0.4799410585020798, train_score=0.5996235285338661\n","n_estimators=30, loss=1.185714687148543, test_score=0.4802280183564441, train_score=0.651698463843335\n","n_estimators=40, loss=1.1815415805443656, test_score=0.4801703984167732, train_score=0.6912720003890884\n","n_estimators=50, loss=1.181012984457532, test_score=0.4809177396067703, train_score=0.7290205414342694\n","n_estimators=60, loss=1.1813479203212083, test_score=0.4814351792198181, train_score=0.7629181392421931\n"]}],"source":["lst1 = []\n","\n","for j in np.arange(10, 61, 10):\n","  kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","  kf.get_n_splits(x)\n","  sum1 = 0\n","  sum2 = 0\n","  sum3 = 0\n","\n","  for train_index, test_index in kf.split(x):\n","      lgbm = LGBMClassifier(n_estimators=j)\n","      x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","      # x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","      # lgbm.fit(x_smote_resampled, y_smote_resampled)\n","      lgbm.fit(x_train, y_train)\n","      a = log_loss(y_test, lgbm.predict_proba(x_test))\n","      b = lgbm.score(x_test, y_test)\n","      c = lgbm.score(x_train, y_train)\n","      # print(a, b, c)\n","      sum1 += a\n","      sum2 += b\n","      sum3 += c\n","  lst1.append(('n_estimators={}, loss={}, test_score={}, train_score={}'.format(j, sum1/5, sum2/5, sum3/5)))\n","  print(lst1[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIw9XsqjpUn4","executionInfo":{"status":"ok","timestamp":1648438207440,"user_tz":240,"elapsed":2417667,"user":{"displayName":"Jenny Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi655rVJdcx-SWLfsJObhFX7f2g-UnTjRLzoblkCQ=s64","userId":"13309933443117035343"}},"outputId":"de7db214-c3a8-48b4-ffe8-9eeb3fd1aa5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["l1=1e-05, l2=1e-05, loss=1.1770842904412016, test_score=0.48528644775054264, train_score=0.5743332466708082\n","l1=1e-05, l2=0.001, loss=1.1769993856049306, test_score=0.4845966769417821, train_score=0.5737297436843373\n","l1=1e-05, l2=0.1, loss=1.1778713162700813, test_score=0.4830444407000294, train_score=0.5724221433843196\n","l1=1e-05, l2=0, loss=1.1770842877014367, test_score=0.48528644775054264, train_score=0.5743332466708082\n","l1=1e-05, l2=0.1, loss=1.1778713162700813, test_score=0.4830444407000294, train_score=0.5724221433843196\n","l1=1e-05, l2=0.3, loss=1.1770897212380103, test_score=0.486320732275426, train_score=0.5717898376604046\n","l1=1e-05, l2=0.5, loss=1.1765700473569853, test_score=0.4867230146065225, train_score=0.5731837047348886\n","l1=1e-05, l2=0.7, loss=1.1777486811569755, test_score=0.4870682386602042, train_score=0.5729107358474302\n","l1=1e-05, l2=0.9, loss=1.1768797227822183, test_score=0.4879876797732206, train_score=0.573054405747721\n","l1=1e-05, l2=1, loss=1.177289605216793, test_score=0.4873554132677841, train_score=0.5720485202909809\n","l1=0.001, l2=1e-05, loss=1.1768637556600612, test_score=0.485573704955513, train_score=0.5747212169322269\n","l1=0.001, l2=0.001, loss=1.1770004684844728, test_score=0.485228712174525, train_score=0.5744769599316126\n","l1=0.001, l2=0.1, loss=1.1774356578353409, test_score=0.485228712174525, train_score=0.572120364532665\n","l1=0.001, l2=0, loss=1.1771432990496131, test_score=0.4858610612773521, train_score=0.5747930663358769\n","l1=0.001, l2=0.1, loss=1.1774356578353409, test_score=0.485228712174525, train_score=0.572120364532665\n","l1=0.001, l2=0.3, loss=1.1776608366067287, test_score=0.4860907976595204, train_score=0.5721922129039216\n","l1=0.001, l2=0.5, loss=1.17644972403818, test_score=0.4864357408820741, train_score=0.5729825078215914\n","l1=0.001, l2=0.7, loss=1.1777836520434168, test_score=0.4894247256940659, train_score=0.5728388606339507\n","l1=0.001, l2=0.9, loss=1.1768092003022312, test_score=0.488505069827834, train_score=0.572853237741433\n","l1=0.001, l2=1, loss=1.1776058810579788, test_score=0.4883325569178619, train_score=0.5727238891993927\n","l1=0.1, l2=1e-05, loss=1.1771679817911642, test_score=0.4867807997409746, train_score=0.5732986348737195\n","l1=0.1, l2=0.001, loss=1.1773817735164511, test_score=0.48701068479844584, train_score=0.5732698951122593\n","l1=0.1, l2=0.1, loss=1.177453236901804, test_score=0.4864359060768552, train_score=0.5734423078711897\n","l1=0.1, l2=0, loss=1.177167979207077, test_score=0.4867807997409746, train_score=0.5732986348737195\n","l1=0.1, l2=0.1, loss=1.177453236901804, test_score=0.4864359060768552, train_score=0.5734423078711897\n","l1=0.1, l2=0.3, loss=1.1770185933913884, test_score=0.48907950164038416, train_score=0.572867584909513\n","l1=0.1, l2=0.5, loss=1.1761828954306492, test_score=0.48804477108959177, train_score=0.57206291907872\n","l1=0.1, l2=0.7, loss=1.1764674160773274, test_score=0.48534411724864784, train_score=0.572867568391222\n","l1=0.1, l2=0.9, loss=1.1774254172377054, test_score=0.4870679578290763, train_score=0.5721203800185626\n","l1=0.1, l2=1, loss=1.1774487679022871, test_score=0.4863204349248199, train_score=0.5725515032826852\n","l1=0, l2=1e-05, loss=1.177088350606133, test_score=0.48591881337284787, train_score=0.5744050909124921\n","l1=0, l2=0.001, loss=1.1769993789836046, test_score=0.4845966769417821, train_score=0.5737297436843373\n","l1=0, l2=0.1, loss=1.177871310606329, test_score=0.4830444407000294, train_score=0.5724221433843196\n","l1=0, l2=0, loss=1.1770883478164045, test_score=0.48591881337284787, train_score=0.5744050909124921\n","l1=0, l2=0.1, loss=1.177871310606329, test_score=0.4830444407000294, train_score=0.5724221433843196\n","l1=0, l2=0.3, loss=1.177089714592031, test_score=0.486320732275426, train_score=0.5717898376604046\n","l1=0, l2=0.5, loss=1.1765700407580675, test_score=0.4867230146065225, train_score=0.5731837047348886\n","l1=0, l2=0.7, loss=1.1777486749879054, test_score=0.4870682386602042, train_score=0.5729107358474302\n","l1=0, l2=0.9, loss=1.1768797161327507, test_score=0.4879876797732206, train_score=0.573054405747721\n","l1=0, l2=1, loss=1.177289598772679, test_score=0.4873554132677841, train_score=0.5720485202909809\n","l1=0.1, l2=1e-05, loss=1.1771679817911642, test_score=0.4867807997409746, train_score=0.5732986348737195\n","l1=0.1, l2=0.001, loss=1.1773817735164511, test_score=0.48701068479844584, train_score=0.5732698951122593\n","l1=0.1, l2=0.1, loss=1.177453236901804, test_score=0.4864359060768552, train_score=0.5734423078711897\n","l1=0.1, l2=0, loss=1.177167979207077, test_score=0.4867807997409746, train_score=0.5732986348737195\n","l1=0.1, l2=0.1, loss=1.177453236901804, test_score=0.4864359060768552, train_score=0.5734423078711897\n","l1=0.1, l2=0.3, loss=1.1770185933913884, test_score=0.48907950164038416, train_score=0.572867584909513\n","l1=0.1, l2=0.5, loss=1.1761828954306492, test_score=0.48804477108959177, train_score=0.57206291907872\n","l1=0.1, l2=0.7, loss=1.1764674160773274, test_score=0.48534411724864784, train_score=0.572867568391222\n","l1=0.1, l2=0.9, loss=1.1774254172377054, test_score=0.4870679578290763, train_score=0.5721203800185626\n","l1=0.1, l2=1, loss=1.1774487679022871, test_score=0.4863204349248199, train_score=0.5725515032826852\n","l1=0.3, l2=1e-05, loss=1.1768608503571512, test_score=0.48724052029748277, train_score=0.5731262035317117\n","l1=0.3, l2=0.001, loss=1.1773733423557284, test_score=0.4867232789181724, train_score=0.5732986421004715\n","l1=0.3, l2=0.1, loss=1.177495185565044, test_score=0.48528615039993656, train_score=0.5726664230975841\n","l1=0.3, l2=0, loss=1.1768608476373201, test_score=0.48724052029748277, train_score=0.5731262035317117\n","l1=0.3, l2=0.1, loss=1.177495185565044, test_score=0.48528615039993656, train_score=0.5726664230975841\n","l1=0.3, l2=0.3, loss=1.1774469828429481, test_score=0.4867230476454788, train_score=0.5720485295825195\n","l1=0.3, l2=0.5, loss=1.1774805045453112, test_score=0.4849414384500765, train_score=0.5714450327904077\n","l1=0.3, l2=0.7, loss=1.1778440882613157, test_score=0.4870679743485543, train_score=0.5719623092657464\n","l1=0.3, l2=0.9, loss=1.1772748421599624, test_score=0.48660810511674313, train_score=0.5704678932894865\n","l1=0.3, l2=1, loss=1.1774314546925737, test_score=0.48695304833929687, train_score=0.5701804987720663\n","l1=0.5, l2=1e-05, loss=1.1776265829675716, test_score=0.48419416333799187, train_score=0.5711863233176088\n","l1=0.5, l2=0.001, loss=1.1774236459806457, test_score=0.4855734736828194, train_score=0.5715599402165885\n","l1=0.5, l2=0.1, loss=1.1770372479084652, test_score=0.4868953623217136, train_score=0.5717898985716026\n","l1=0.5, l2=0, loss=1.1776265803730084, test_score=0.48419416333799187, train_score=0.5711863233176088\n","l1=0.5, l2=0.1, loss=1.1770372479084652, test_score=0.4868953623217136, train_score=0.5717898985716026\n","l1=0.5, l2=0.3, loss=1.1768284710957704, test_score=0.48609084721795465, train_score=0.5718473832564883\n","l1=0.5, l2=0.5, loss=1.1775867296493814, test_score=0.48586104475787406, train_score=0.5724364853904337\n","l1=0.5, l2=0.7, loss=1.1766053865836443, test_score=0.4871253299765753, train_score=0.5710282907633402\n","l1=0.5, l2=0.9, loss=1.1775630618581547, test_score=0.4875851661694304, train_score=0.5694045221154673\n","l1=0.5, l2=1, loss=1.1778535881196628, test_score=0.48775764604044625, train_score=0.5714450224664759\n","l1=0.7, l2=1e-05, loss=1.1768977763071806, test_score=0.4872403055442673, train_score=0.5701517497190678\n","l1=0.7, l2=0.001, loss=1.1771370520272788, test_score=0.4852862825557615, train_score=0.5700799003154178\n","l1=0.7, l2=0.1, loss=1.1763314426256088, test_score=0.488906988730412, train_score=0.5706259454592256\n","l1=0.7, l2=0, loss=1.1768977736511155, test_score=0.4872403055442673, train_score=0.5701517497190678\n","l1=0.7, l2=0.1, loss=1.1763314426256088, test_score=0.488906988730412, train_score=0.5706259454592256\n","l1=0.7, l2=0.3, loss=1.1779453810686937, test_score=0.48482611597334413, train_score=0.571545545558422\n","l1=0.7, l2=0.5, loss=1.1777246244345414, test_score=0.48545861375147437, train_score=0.5709564227766131\n","l1=0.7, l2=0.7, loss=1.1774533120635158, test_score=0.48545841551773694, train_score=0.5694332783952183\n","l1=0.7, l2=0.9, loss=1.1771725303803373, test_score=0.48643537745355553, train_score=0.5712582160817725\n","l1=0.7, l2=1, loss=1.177124776842491, test_score=0.48712524737918483, train_score=0.5697781606947039\n","l1=0.9, l2=1e-05, loss=1.1770375757001663, test_score=0.48505639749829027, train_score=0.5703241614456049\n","l1=0.9, l2=0.001, loss=1.1769894737856383, test_score=0.48505639749829027, train_score=0.5701804636706982\n","l1=0.9, l2=0.1, loss=1.1780791447244627, test_score=0.48792996071668104, train_score=0.570827126886625\n","l1=0.9, l2=0, loss=1.1770375728558313, test_score=0.48505639749829027, train_score=0.5703241614456049\n","l1=0.9, l2=0.1, loss=1.1780791447244627, test_score=0.48792996071668104, train_score=0.570827126886625\n","l1=0.9, l2=0.3, loss=1.178026613729996, test_score=0.4868377589015208, train_score=0.5702092591813901\n","l1=0.9, l2=0.5, loss=1.1776061769032231, test_score=0.4860333429146307, train_score=0.5698356536387352\n","l1=0.9, l2=0.7, loss=1.1773119594917905, test_score=0.4859183508274606, train_score=0.5705253531969361\n","l1=0.9, l2=0.9, loss=1.1773124408753903, test_score=0.48637828613718437, train_score=0.5683412066906801\n","l1=0.9, l2=1, loss=1.1772298641396248, test_score=0.48568831709468635, train_score=0.5694907475942065\n","l1=1, l2=1e-05, loss=1.1772253791157585, test_score=0.48591828474954823, train_score=0.570539761276214\n","l1=1, l2=0.001, loss=1.177138721310471, test_score=0.48632079835333847, train_score=0.5700943135566615\n","l1=1, l2=0.1, loss=1.1778369176773635, test_score=0.486607939921962, train_score=0.5700080653652724\n","l1=1, l2=0, loss=1.1772253762860516, test_score=0.48591828474954823, train_score=0.570539761276214\n","l1=1, l2=0.1, loss=1.1778369176773635, test_score=0.486607939921962, train_score=0.5700080653652724\n","l1=1, l2=0.3, loss=1.1771730029537366, test_score=0.4867802876371529, train_score=0.5702954454291882\n","l1=1, l2=0.5, loss=1.1769168544004422, test_score=0.48384907144013506, train_score=0.5687147926178643\n","l1=1, l2=0.7, loss=1.1777020520526786, test_score=0.48620582278564656, train_score=0.5696919527666491\n","l1=1, l2=0.9, loss=1.1773909799945086, test_score=0.4867228989701758, train_score=0.5686429721212235\n","l1=1, l2=1, loss=1.177613712419016, test_score=0.486895444919104, train_score=0.5689590940113854\n"]}],"source":["lst1 = []\n","kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","kf.get_n_splits(x)\n","\n","for i in [1e-5, 1e-3, 1e-1, 0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]:\n","  for j in [1e-5, 1e-3, 1e-1, 0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]:\n","    sum1 = 0\n","    sum2 = 0\n","    sum3 = 0\n","\n","    for train_index, test_index in kf.split(x):\n","        lgbm = LGBMClassifier(n_estimators=50, learning_rate=0.1, max_depth=9, \n","                              num_leaves=20, min_child_samples=100, subsample=1, \n","                              colsample_bytree=0.7, reg_alpha=i, reg_lambda=j)\n","        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        # x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","        # lgbm.fit(x_smote_resampled, y_smote_resampled)\n","        lgbm.fit(x_train, y_train)\n","        a = log_loss(y_test, lgbm.predict_proba(x_test))\n","        b = lgbm.score(x_test, y_test)\n","        c = lgbm.score(x_train, y_train)\n","        # print(a, b, c)\n","        sum1 += a\n","        sum2 += b\n","        sum3 += c\n","    lst1.append(('l1={}, l2={}, loss={}, test_score={}, train_score={}'.format(i, j, sum1/5, sum2/5, sum3/5)))\n","    print(lst1[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4k3VGVbrOQE","outputId":"7233248b-9f0d-44cf-ada8-c5a00e5b4611"},"outputs":[{"name":"stdout","output_type":"stream","text":["min_child_weight=0.003, min_child_samples=5, loss=1.1788577403565923, test_score=0.47925113901801614, train_score=0.59544197789768\n","min_child_weight=0.003, min_child_samples=10, loss=1.1774531156054837, test_score=0.48045836595930264, train_score=0.5962035743496173\n","min_child_weight=0.003, min_child_samples=15, loss=1.1776140720016235, test_score=0.4822977933281131, train_score=0.5951114974831132\n","min_child_weight=0.003, min_child_samples=20, loss=1.177857998995282, test_score=0.4763198402236076, train_score=0.5972669073250887\n","min_child_weight=0.003, min_child_samples=25, loss=1.179072225983749, test_score=0.4752278036032286, train_score=0.5963904055117573\n","min_child_weight=0.003, min_child_samples=30, loss=1.1775995701717448, test_score=0.47810197804230964, train_score=0.5943786955094748\n","min_child_weight=0.003, min_child_samples=35, loss=1.1770797888901996, test_score=0.47545763910226546, train_score=0.5939475794721044\n","min_child_weight=0.003, min_child_samples=40, loss=1.1786223090607073, test_score=0.47781463823994874, train_score=0.5938757042586251\n"]}],"source":["lst2 = []\n","\n","for i in np.arange(0.0030, 0.0031, 0.0005):\n","  for j in np.arange(5, 41, 5):\n","    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","    kf.get_n_splits(x)\n","    sum1 = 0\n","    sum2 = 0\n","    sum3 = 0\n","\n","    for train_index, test_index in kf.split(x):\n","        lgbm = LGBMClassifier(n_estimators=350, learning_rate=0.1, max_depth=6, num_leaves=6, \n","                              min_child_weight=i, min_child_samples=j)\n","        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","        lgbm.fit(x_smote_resampled, y_smote_resampled)\n","        a = log_loss(y_test, lgbm.predict_proba(x_test))\n","        b = lgbm.score(x_test, y_test)\n","        c = lgbm.score(x_train, y_train)\n","        # print(a, b, c)\n","        sum1 += a\n","        sum2 += b\n","        sum3 += c\n","    lst2.append(('min_child_weight={}, min_child_samples={}, loss={}, test_score={}, train_score={}'.format(i, j, sum1/5, sum2/5, sum3/5)))\n","    print(lst2[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAWvVuD0hkMR","outputId":"760398ea-6624-4f42-dc9d-fd01af0a77a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["subsample=0.7, colsample_bytree=0.7, loss=1.1780181201822442, test_score=0.47999852976644763, train_score=0.5918783662018587\n"]}],"source":["lst3 = []\n","sl = [0.7, 0.8, 0.9, 1.0]\n","cl = [0.7, 0.8, 0.9, 1.0]\n","\n","for i in sl:\n","  for j in cl:\n","    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","    kf.get_n_splits(x)\n","    sum1 = 0\n","    sum2 = 0\n","    sum3 = 0\n","\n","    for train_index, test_index in kf.split(x):\n","        lgbm = LGBMClassifier(n_estimators=350, learning_rate=0.1, max_depth=6, num_leaves=6, \n","                              min_child_weight=0.0005, min_child_samples=35, subsample=i, colsample_bytree=j)\n","        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","        lgbm.fit(x_smote_resampled, y_smote_resampled)\n","        a = log_loss(y_test, lgbm.predict_proba(x_test))\n","        b = lgbm.score(x_test, y_test)\n","        c = lgbm.score(x_train, y_train)\n","        # print(a, b, c)\n","        sum1 += a\n","        sum2 += b\n","        sum3 += c\n","    lst3.append(('subsample={}, colsample_bytree={}, loss={}, test_score={}, train_score={}'.format(i, j, sum1/5, sum2/5, sum3/5)))\n","    print(lst3[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0k1TmGZU3UMi"},"outputs":[],"source":["lst4 = []\n","\n","# for i in np.arange(0.7, 1.1, 0.1):\n","for j in np.arange(0, 0.5, 0.1):\n","  kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","  kf.get_n_splits(x)\n","  sum1 = 0\n","  sum2 = 0\n","  sum3 = 0\n","\n","  for train_index, test_index in kf.split(x):\n","      lgbm = LGBMClassifier(n_estimators=350, learning_rate=0.1, max_depth=6, num_leaves=6, \n","                            min_child_weight=0.0005, min_child_samples=35)\n","      x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","      x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","      lgbm.fit(x_smote_resampled, y_smote_resampled)\n","      a = log_loss(y_test, lgbm.predict_proba(x_test))\n","      b = lgbm.score(x_test, y_test)\n","      c = lgbm.score(x_train, y_train)\n","      # print(a, b, c)\n","      sum1 += a\n","      sum2 += b\n","      sum3 += c\n","  lst4.append(('L1={}, loss={}, test_score={}, train_score={}'.format(j, sum1/5, sum2/5, sum3/5)))\n","  print(lst4[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-CpAQNZt64t"},"outputs":[],"source":["x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mY7XiFptDIjM"},"outputs":[],"source":["x_smote_resampled1, y_smote_resampled1 = SMOTE().fit_resample(x, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7nWAt0luXlg","outputId":"4302e3d2-c05a-4143-e568-4e1ee7a904d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["depth =  300\n","1.1816957406188682 0.47988505747126436 0.6965799683862623\n","1.1999709167898063 0.4704022988505747 0.7003879867797097\n","1.1892444634321586 0.47155172413793106 0.7044834027877569\n","1.1714409109419452 0.48074712643678164 0.6965799683862623\n","1.2118905153856503 0.45488505747126434 0.6983762034775112\n","300   score_train  0.6992815059635005 score_test  0.47149425287356317 loss  1.1908485094336858\n","depth =  310\n","1.1809395468172739 0.4732758620689655 0.6937778416439143\n","1.200981353941164 0.4752873563218391 0.6980169564592614\n"]}],"source":["lst1 = []\n","for i in np.arange(300, 410, 10):\n","      print(\"depth = \", i)\n","      sum1 = 0\n","      sum2 = 0\n","      sum3 = 0\n","      for k in range(1, 6):\n","        lgbm = LGBMClassifier()\n","        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=5 * k)\n","        x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","        lgbm.fit(x_smote_resampled, y_smote_resampled)\n","        a = log_loss(y_test, lgbm.predict_proba(x_test))\n","        b = lgbm.score(x_test,y_test)\n","        c = lgbm.score(x_train,y_train)\n","        print(a, b, c)\n","        sum1 += a\n","        sum2 += b\n","        sum3 += c\n","      lst1.append((i, sum3/5, sum2/5, sum1/5))\n","      print(i,\" \", \"score_train \", sum3/5, \"score_test \", sum2/5, \"loss \", sum1/5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"6ZryMwItB8AK","outputId":"1b1a17ba-7231-4eb0-e1d0-e20db0b15a87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 16 candidates, totalling 80 fits\n","[CV 1/5] END ....reg_alpha=0.1, reg_lambda=0.1;, score=-1.873 total time= 1.4min\n","[CV 2/5] END ....reg_alpha=0.1, reg_lambda=0.1;, score=-1.635 total time= 1.3min\n","[CV 3/5] END ....reg_alpha=0.1, reg_lambda=0.1;, score=-1.750 total time= 1.4min\n","[CV 4/5] END ....reg_alpha=0.1, reg_lambda=0.1;, score=-1.234 total time= 1.3min\n","[CV 5/5] END ....reg_alpha=0.1, reg_lambda=0.1;, score=-1.737 total time= 1.3min\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-73-ff5c645adebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           colsample_bytree = 0.8, subsample = 0.8)\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_log_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_smote_resampled1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote_resampled1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["params={'n_estimators':np.arange(50, 600, 50)}\n","\n","clf = LGBMClassifier()\n","grid = GridSearchCV(clf, params, cv=5, scoring=\"neg_log_loss\", verbose=3)\n","grid.fit(x_smote_resampled1, y_smote_resampled1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MBFwdJFgWcU","outputId":"1def5e38-d726-431f-9b06-4c3ebb168913"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.1762527731049344 0.4761494252873563 0.5954878574507831\n"]}],"source":["a = log_loss(y_test, lgbm.predict_proba(x_test))\n","b = lgbm.score(x_test,y_test)\n","c = lgbm.score(x_train,y_train)\n","print(a, b, c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBvUwlUsY0L3"},"outputs":[],"source":["def getloss(x):\n","  return x[4]\n","\n","lst.sort(key=getloss)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-_DII_WeXHW","outputId":"17dbe9ed-66a1-4a0c-e8ae-45695d32df00"},"outputs":[{"data":{"text/plain":["[(6, 8, 0.592886909038655, 0.4813218390804598, 1.1759208512624064),\n"," (7, 10, 0.6246443454519327, 0.48178160919540225, 1.1762469758322576),\n"," (7, 8, 0.5935335536715045, 0.4787356321839081, 1.1765190119704063),\n"," (8, 8, 0.592786319873545, 0.48293103448275854, 1.176619052722192),\n"," (7, 12, 0.6574651530392297, 0.47793103448275864, 1.1776833275223224),\n"," (5, 8, 0.5901853714614169, 0.47988505747126436, 1.1777031073434425),\n"," (8, 10, 0.6260382238827418, 0.48166666666666663, 1.1779081836390375),\n"," (6, 12, 0.6568616180485702, 0.4780459770114942, 1.1784719145911111),\n"," (8, 12, 0.6583417157637592, 0.4789655172413793, 1.1785083280552167),\n"," (5, 10, 0.6221296163241845, 0.48091954022988503, 1.1788359522583838),\n"," (6, 10, 0.6247449346170427, 0.4772413793103449, 1.1793744038092502),\n"," (5, 12, 0.6526943526368731, 0.4801724137931034, 1.180569453690227),\n"," (7, 14, 0.6877712314987786, 0.48166666666666663, 1.1810030640877518),\n"," (8, 14, 0.6903003305072568, 0.4791954022988506, 1.1811871838571975),\n"," (8, 16, 0.7193849691047565, 0.4804022988505747, 1.1815774904752312),\n"," (5, 14, 0.6790774536571347, 0.4777586206896552, 1.1816960247291224),\n"," (6, 14, 0.6852565023710303, 0.4777586206896552, 1.1825929140878833),\n"," (5, 16, 0.701350768788619, 0.47620689655172416, 1.1830810612332008),\n"," (7, 16, 0.7163672941514585, 0.4817241379310345, 1.1833886894009844),\n"," (6, 16, 0.7128754131340709, 0.4764367816091954, 1.1839471787871723)]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["lst"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3-XuLzc1AEj","outputId":"08ade214-a884-437b-87fa-6431e74e6a57"},"outputs":[{"name":"stdout","output_type":"stream","text":["year          int64\n","personid      int64\n","x1          float64\n","x2          float64\n","x3          float64\n","             ...   \n","x1201         int64\n","x1202         int64\n","x1203       float64\n","x1204       float64\n","x1205       float64\n","Length: 287, dtype: object\n"]}],"source":["print(x.dtypes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqntYXAmRCZ1","outputId":"65e05471-1b3d-4c30-bf20-f199e20c456d"},"outputs":[{"name":"stdout","output_type":"stream","text":["max_depth =  5 num_leaves =  7\n","1.1798588033859734 0.4850574712643678 0.5747233797959477\n","1.1839258883812152 0.4755747126436782 0.5767351630981463\n","1.164562112132989 0.4810344827586207 0.5729989941083489\n","1.1797660087954605 0.4853448275862069 0.5755855726397471\n","1.1808109293727702 0.4818965517241379 0.5778129041528955\n","5   7 score_train  0.5755712027590171 score_test  0.48178160919540236 loss  1.1777847484136816\n","max_depth =  5 num_leaves =  8\n","1.178209060324411 0.47586206896551725 0.591320592039086\n","1.1863114191162654 0.4752873563218391 0.5906739474062366\n","1.164302239858156 0.48735632183908045 0.5939071705704843\n","1.1777455599684377 0.4885057471264368 0.5935479235522345\n","1.1758018837517723 0.4810344827586207 0.5922546342865355\n","5   8 score_train  0.5923408535709153 score_test  0.48160919540229885 loss  1.1764740326038083\n","max_depth =  5 num_leaves =  9\n","1.1818874415391345 0.47701149425287354 0.6069119126311252\n","1.183848612399002 0.4721264367816092 0.6083489007041242\n","1.163307309306151 0.48477011494252875 0.6073430090530249\n","1.1780877900409636 0.4896551724137931 0.6089955453369738\n","1.1769697658046714 0.4795977011494253 0.6079896536858744\n","5   9 score_train  0.6079178042822244 score_test  0.48063218390804596 loss  1.1768201838179846\n","max_depth =  6 num_leaves =  7\n","1.1786327531329486 0.47988505747126436 0.5727115964937491\n","1.1877788361644679 0.4672413793103448 0.5730708435119989\n","1.1644165046264685 0.4870689655172414 0.5741485845667481\n","1.178794607448392 0.48563218390804597 0.5768788619054462\n","1.177485018173562 0.4795977011494253 0.5753700244287973\n","6   7 score_train  0.5744359821813478 score_test  0.47988505747126436 loss  1.1774215439091678\n","max_depth =  6 num_leaves =  8\n","1.1812426446646243 0.47442528735632183 0.5929012789193849\n","1.1822503149021861 0.47126436781609193 0.5895243569478373\n","1.1656842706026673 0.4827586206896552 0.5949849116252335\n","1.1808276306876775 0.48649425287356324 0.5921827848828854\n","1.17937889728336 0.4732758620689655 0.5948412128179336\n","6   8 score_train  0.5928869090386549 score_test  0.47764367816091957 loss  1.1778767516281032\n","max_depth =  6 num_leaves =  9\n","1.1753973956123982 0.4810344827586207 0.6079178042822244\n","1.1865823617317073 0.4704022988505747 0.6082052018968243\n","1.1688881410521503 0.47902298850574715 0.6105043828136226\n","1.1800651684326897 0.4836206896551724 0.6112228768501221\n","1.1781531218056676 0.4778735632183908 0.6117258226756718\n","6   9 score_train  0.6099152177036931 score_test  0.47839080459770117 loss  1.1778172377269227\n","max_depth =  7 num_leaves =  7\n","1.1762909965272517 0.48160919540229885 0.5754418738324472\n","1.1848861368567523 0.4681034482758621 0.5737174881448484\n","1.166177499815563 0.48247126436781607 0.5721368012645495\n","1.1756541354131282 0.48563218390804597 0.5753700244287973\n","1.1761923886549235 0.4752873563218391 0.5763040666762466\n","7   7 score_train  0.5745940508693778 score_test  0.47862068965517235 loss  1.1758402314535237\n","max_depth =  7 num_leaves =  8\n","1.178231115997059 0.4781609195402299 0.5898836039660871\n","1.1815933424003864 0.47270114942528735 0.5905302485989367\n","1.164110129281947 0.478735632183908 0.5936197729558844\n","1.178450096106378 0.49195402298850577 0.5919672366719356\n","1.1773410622001017 0.4813218390804598 0.5922546342865355\n","7   8 score_train  0.5916510992958759 score_test  0.4805747126436781 loss  1.1759451491971746\n","max_depth =  7 num_leaves =  9\n","1.1803537259812704 0.47586206896551725 0.6069837620347751\n","1.1855928739120642 0.47413793103448276 0.6089955453369738\n","1.1665112121336487 0.478735632183908 0.607271159649375\n","1.175187704966446 0.48419540229885055 0.6087081477223739\n","1.1787260236650725 0.4795977011494253 0.609857738180773\n","7   9 score_train  0.6083632705848542 score_test  0.4785057471264368 loss  1.1772743081317005\n"]}],"source":["lst1 = []\n","for i in np.arange(5, 8):\n","  for j in np.arange(7, 10, 1):\n","    print(\"max_depth = \", i, \"num_leaves = \", j)\n","    sum1 = 0\n","    sum2 = 0\n","    sum3 = 0\n","    for k in range(1, 6):\n","      lgbm = LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=i, num_leaves=j,\n","          colsample_bytree = 0.8, subsample = 0.8, lambda_l1= 0.1,\n","          lambda_l2=0.2)\n","      x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=k)\n","      x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","      lgbm.fit(x_smote_resampled, y_smote_resampled)\n","      a = log_loss(y_test, lgbm.predict_proba(x_test))\n","      b = lgbm.score(x_test,y_test)\n","      c = lgbm.score(x_train,y_train)\n","      print(a, b, c)\n","      sum1 += a\n","      sum2 += b\n","      sum3 += c\n","    lst1.append((i, j, sum3/5, sum2/5, sum1/5))\n","    print(i,\" \", j, \"score_train \", sum3/5, \"score_test \", sum2/5, \"loss \", sum1/5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EN6zQUy4hgj","outputId":"4f1768c2-a39f-4d3d-95a6-f75551d4469c"},"outputs":[{"data":{"text/plain":["LGBMClassifier(colsample_bytree=0.8, lambda_l1=0.1, lambda_l2=0.2,\n","               learning_rate=0.05, max_depth=5, n_estimators=500, num_leaves=7,\n","               subsample=0.8)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["x, y = df.iloc[:,:-1],df.iloc[:,-1]\n","lgbm1 = LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=5, num_leaves=7,\n","          colsample_bytree = 0.8, subsample = 0.8, lambda_l1= 0.1,\n","          lambda_l2=0.2)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n","x_smote_resampled, y_smote_resampled = SMOTE().fit_resample(x_train, y_train)\n","lgbm1.fit(x_smote_resampled, y_smote_resampled)"]},{"cell_type":"markdown","source":["##### Gradient Boosting prediction"],"metadata":{"id":"08j-JlIHkTur"}},{"cell_type":"code","source":["x, y = df.iloc[:,:-1],df.iloc[:,-1]\n","gb = GradientBoostingClassifier(n_estimators=90)\n","# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","gb.fit(x, y)"],"metadata":{"id":"i0YDKBaKkPmc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_isQogxBgpt8"},"outputs":[],"source":["df2 = pd.read_csv(\"test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8JebxXPfuMl"},"outputs":[],"source":["pred = gb.predict_proba(df1).T\n","pred = pd.DataFrame(pred)\n","pred = pred.append(df2['uniqueid'])\n","pred = pred.T\n","pred.columns = ['p1', 'p2', 'p3', 'p4', 'p5', 'uniqueid']\n","pred = pred[['uniqueid', 'p1', 'p2', 'p3', 'p4', 'p5']]\n","pred['uniqueid'] = pred['uniqueid'].astype(int)\n","pred.to_csv('result_lgb_6_8_08_08_005.csv', index=False)"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}